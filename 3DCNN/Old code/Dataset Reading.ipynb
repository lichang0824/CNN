{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0322f8c-c40d-4ac9-9fd0-a3d2260fba75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c4066-053d-42cf-932b-ab84b77fda31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Binvox code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1343a6-d48b-4a8c-9d93-082f55bfbf29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Binvox Read Write\n",
    "#  Copyright (C) 2012 Daniel Maturana\n",
    "#  This file is part of binvox-rw-py.\n",
    "#\n",
    "#  binvox-rw-py is free software: you can redistribute it and/or modify\n",
    "#  it under the terms of the GNU General Public License as published by\n",
    "#  the Free Software Foundation, either version 3 of the License, or\n",
    "#  (at your option) any later version.\n",
    "#\n",
    "#  binvox-rw-py is distributed in the hope that it will be useful,\n",
    "#  but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#  GNU General Public License for more details.\n",
    "#\n",
    "#  You should have received a copy of the GNU General Public License\n",
    "#  along with binvox-rw-py. If not, see <http://www.gnu.org/licenses/>.\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Voxels(object):\n",
    "    \"\"\" Holds a binvox model.\n",
    "    data is either a three-dimensional numpy boolean array (dense representation)\n",
    "    or a two-dimensional numpy float array (coordinate representation).\n",
    "\n",
    "    dims, translate and scale are the model metadata.\n",
    "\n",
    "    dims are the voxel dimensions, e.g. [32, 32, 32] for a 32x32x32 model.\n",
    "\n",
    "    scale and translate relate the voxels to the original model coordinates.\n",
    "\n",
    "    To translate voxel coordinates i, j, k to original coordinates x, y, z:\n",
    "\n",
    "    x_n = (i+.5)/dims[0]\n",
    "    y_n = (j+.5)/dims[1]\n",
    "    z_n = (k+.5)/dims[2]\n",
    "    x = scale*x_n + translate[0]\n",
    "    y = scale*y_n + translate[1]\n",
    "    z = scale*z_n + translate[2]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, dims, translate, scale, axis_order):\n",
    "        self.data = data\n",
    "        self.dims = dims\n",
    "        self.translate = translate\n",
    "        self.scale = scale\n",
    "        assert (axis_order in ('xzy', 'xyz'))\n",
    "        self.axis_order = axis_order\n",
    "\n",
    "    def clone(self):\n",
    "        data = self.data.copy()\n",
    "        dims = self.dims[:]\n",
    "        translate = self.translate[:]\n",
    "        return Voxels(data, dims, translate, self.scale, self.axis_order)\n",
    "\n",
    "    def write(self, fp):\n",
    "        write(self, fp)\n",
    "\n",
    "def read_header(fp):\n",
    "    \"\"\" Read binvox header. Mostly meant for internal use.\n",
    "    \"\"\"\n",
    "    line = fp.readline().strip()\n",
    "    if not line.startswith(b'#binvox'):\n",
    "        raise IOError('Not a binvox file')\n",
    "    dims = list(map(int, fp.readline().strip().split(b' ')[1:]))\n",
    "    translate = list(map(float, fp.readline().strip().split(b' ')[1:]))\n",
    "    scale = list(map(float, fp.readline().strip().split(b' ')[1:]))[0]\n",
    "    line = fp.readline()\n",
    "    return dims, translate, scale\n",
    "\n",
    "def read_as_3d_array(fp, fix_coords=True):\n",
    "    \"\"\" Read binary binvox format as array.\n",
    "\n",
    "    Returns the model with accompanying metadata.\n",
    "\n",
    "    Voxels are stored in a three-dimensional numpy array, which is simple and\n",
    "    direct, but may use a lot of memory for large models. (Storage requirements\n",
    "    are 8*(d^3) bytes, where d is the dimensions of the binvox model. Numpy\n",
    "    boolean arrays use a byte per element).\n",
    "\n",
    "    Doesn't do any checks on input except for the '#binvox' line.\n",
    "    \"\"\"\n",
    "    dims, translate, scale = read_header(fp)\n",
    "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
    "    # if just using reshape() on the raw data:\n",
    "    # indexing the array as array[i,j,k], the indices map into the\n",
    "    # coords as:\n",
    "    # i -> x\n",
    "    # j -> z\n",
    "    # k -> y\n",
    "    # if fix_coords is true, then data is rearranged so that\n",
    "    # mapping is\n",
    "    # i -> x\n",
    "    # j -> y\n",
    "    # k -> z\n",
    "    values, counts = raw_data[::2], raw_data[1::2]\n",
    "    data = np.repeat(values, counts).astype(bool)\n",
    "    data = data.reshape(dims)\n",
    "    if fix_coords:\n",
    "        # xzy to xyz TODO the right thing\n",
    "        data = np.transpose(data, (0, 2, 1))\n",
    "        axis_order = 'xyz'\n",
    "    else:\n",
    "        axis_order = 'xzy'\n",
    "    return Voxels(data, dims, translate, scale, axis_order)\n",
    "\n",
    "def read_as_coord_array(fp, fix_coords=True):\n",
    "    \"\"\" Read binary binvox format as coordinates.\n",
    "\n",
    "    Returns binvox model with voxels in a \"coordinate\" representation, i.e.  an\n",
    "    3 x N array where N is the number of nonzero voxels. Each column\n",
    "    corresponds to a nonzero voxel and the 3 rows are the (x, z, y) coordinates\n",
    "    of the voxel.  (The odd ordering is due to the way binvox format lays out\n",
    "    data).  Note that coordinates refer to the binvox voxels, without any\n",
    "    scaling or translation.\n",
    "\n",
    "    Use this to save memory if your model is very sparse (mostly empty).\n",
    "\n",
    "    Doesn't do any checks on input except for the '#binvox' line.\n",
    "    \"\"\"\n",
    "    dims, translate, scale = read_header(fp)\n",
    "    raw_data = np.frombuffer(fp.read(), dtype=np.uint8)\n",
    "\n",
    "    values, counts = raw_data[::2], raw_data[1::2]\n",
    "\n",
    "    sz = np.prod(dims)\n",
    "    index, end_index = 0, 0\n",
    "    end_indices = np.cumsum(counts)\n",
    "    indices = np.concatenate(([0], end_indices[:-1])).astype(end_indices.dtype)\n",
    "\n",
    "    values = values.astype(np.bool)\n",
    "    indices = indices[values]\n",
    "    end_indices = end_indices[values]\n",
    "\n",
    "    nz_voxels = []\n",
    "    for index, end_index in zip(indices, end_indices):\n",
    "        nz_voxels.extend(range(index, end_index))\n",
    "    nz_voxels = np.array(nz_voxels)\n",
    "    # TODO are these dims correct?\n",
    "    # according to docs,\n",
    "    # index = x * wxh + z * width + y; // wxh = width * height = d * d\n",
    "\n",
    "    x = nz_voxels / (dims[0]*dims[1])\n",
    "    zwpy = nz_voxels % (dims[0]*dims[1]) # z*w + y\n",
    "    z = zwpy / dims[0]\n",
    "    y = zwpy % dims[0]\n",
    "    if fix_coords:\n",
    "        data = np.vstack((x, y, z))\n",
    "        axis_order = 'xyz'\n",
    "    else:\n",
    "        data = np.vstack((x, z, y))\n",
    "        axis_order = 'xzy'\n",
    "\n",
    "    #return Voxels(data, dims, translate, scale, axis_order)\n",
    "    return Voxels(np.ascontiguousarray(data), dims, translate, scale, axis_order)\n",
    "\n",
    "def dense_to_sparse(voxel_data, dtype=int):\n",
    "    \"\"\" From dense representation to sparse (coordinate) representation.\n",
    "    No coordinate reordering.\n",
    "    \"\"\"\n",
    "    if voxel_data.ndim!=3:\n",
    "        raise ValueError('voxel_data is wrong shape; should be 3D array.')\n",
    "    return np.asarray(np.nonzero(voxel_data), dtype)\n",
    "\n",
    "def sparse_to_dense(voxel_data, dims, dtype=bool):\n",
    "    if voxel_data.ndim!=2 or voxel_data.shape[0]!=3:\n",
    "        raise ValueError('voxel_data is wrong shape; should be 3xN array.')\n",
    "    if np.isscalar(dims):\n",
    "        dims = [dims]*3\n",
    "    dims = np.atleast_2d(dims).T\n",
    "    # truncate to integers\n",
    "    xyz = voxel_data.astype(np.int)\n",
    "    # discard voxels that fall outside dims\n",
    "    valid_ix = ~np.any((xyz < 0) | (xyz >= dims), 0)\n",
    "    xyz = xyz[:,valid_ix]\n",
    "    out = np.zeros(dims.flatten(), dtype=dtype)\n",
    "    out[tuple(xyz)] = True\n",
    "    return out\n",
    "\n",
    "#def get_linear_index(x, y, z, dims):\n",
    "    #\"\"\" Assuming xzy order. (y increasing fastest.\n",
    "    #TODO ensure this is right when dims are not all same\n",
    "    #\"\"\"\n",
    "    #return x*(dims[1]*dims[2]) + z*dims[1] + y\n",
    "\n",
    "def write(voxel_model, fp):\n",
    "    \"\"\" Write binary binvox format.\n",
    "\n",
    "    Note that when saving a model in sparse (coordinate) format, it is first\n",
    "    converted to dense format.\n",
    "\n",
    "    Doesn't check if the model is 'sane'.\n",
    "\n",
    "    \"\"\"\n",
    "    if voxel_model.data.ndim==2:\n",
    "        # TODO avoid conversion to dense\n",
    "        dense_voxel_data = sparse_to_dense(voxel_model.data, voxel_model.dims)\n",
    "    else:\n",
    "        dense_voxel_data = voxel_model.data\n",
    "\n",
    "    fp.write('#binvox 1\\n')\n",
    "    fp.write('dim '+' '.join(map(str, voxel_model.dims))+'\\n')\n",
    "    fp.write('translate '+' '.join(map(str, voxel_model.translate))+'\\n')\n",
    "    fp.write('scale '+str(voxel_model.scale)+'\\n')\n",
    "    fp.write('data\\n')\n",
    "    if not voxel_model.axis_order in ('xzy', 'xyz'):\n",
    "        raise ValueError('Unsupported voxel model axis order')\n",
    "\n",
    "    if voxel_model.axis_order=='xzy':\n",
    "        voxels_flat = dense_voxel_data.flatten()\n",
    "    elif voxel_model.axis_order=='xyz':\n",
    "        voxels_flat = np.transpose(dense_voxel_data, (0, 2, 1)).flatten()\n",
    "\n",
    "    # keep a sort of state machine for writing run length encoding\n",
    "    state = voxels_flat[0]\n",
    "    ctr = 0\n",
    "    for c in voxels_flat:\n",
    "        if c==state:\n",
    "            ctr += 1\n",
    "            # if ctr hits max, dump\n",
    "            if ctr==255:\n",
    "                fp.write(chr(state))\n",
    "                fp.write(chr(ctr))\n",
    "                ctr = 0\n",
    "        else:\n",
    "            # if switch state, dump\n",
    "            fp.write(chr(state))\n",
    "            fp.write(chr(ctr))\n",
    "            state = c\n",
    "            ctr = 1\n",
    "    # flush out remainders\n",
    "    if ctr > 0:\n",
    "        fp.write(chr(state))\n",
    "        fp.write(chr(ctr))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    doctest.testmod()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611a0bb7-080a-4750-9da8-d7e73ae4f71b",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a25c98-0bcf-4399-b213-3dcb0241592c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, input_folder_path, label_file_path, transform = None):\n",
    "        self.input_folder_path = input_folder_path\n",
    "        self.label_file_path = label_file_path\n",
    "        self.transform = transform\n",
    "        self.input_paths, self.input_names = self.load_input_paths_names()\n",
    "        self.labels = self.load_labels()\n",
    "    \n",
    "    def load_input_paths_names(self):\n",
    "        list_of_file_paths = []\n",
    "        list_of_file_names = []\n",
    "        directory = os.fsencode(self.input_folder_path)\n",
    "        for file in os.listdir(directory):\n",
    "            list_of_file_paths.append(self.input_folder_path + os.fsdecode(file))\n",
    "            list_of_file_names.append(os.fsdecode(file))\n",
    "        return list_of_file_paths, list_of_file_names\n",
    "    \n",
    "    def load_labels(self):\n",
    "        csv = pd.read_csv(self.label_file_path, header = None)\n",
    "        return pd.Series(data = csv[1].values, index = csv[0].values, dtype = 'float32')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.load_sample_from_disk(self.input_paths[idx])\n",
    "        \n",
    "        # debug\n",
    "        print(self.input_names[idx].replace('binvox', 'stl'))\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample, self.labels[self.input_names[idx].replace('binvox', 'stl')]\n",
    "    \n",
    "    def load_sample_from_disk(self, file_path):\n",
    "        return read_as_3d_array(open(file_path, 'rb')).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f3d659-4366-4cbc-ad6c-e026c8289027",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_folder_path = '../AdditiveParts/data/parts_0, files 1 through 3950/Binvox_files_default_res/'\n",
    "label_file_path = '../AdditiveParts/data/Tweaker Orientation Score/Tweaker Orientation Score/parts0_1-3950.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885be16b-e06c-41fc-81f0-e3e61f58e895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(voxel):\n",
    "    return torch.unsqueeze(torch.tensor(voxel), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c68a378-8d93-4764-a98c-d92b6bf7c1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(input_folder_path = input_folder_path, label_file_path = label_file_path, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b9188e-5604-4433-a276-634f85b3e0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataLoader = DataLoader(dataset, batch_size = 2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68612a88-377f-4b08-92f6-2486f14c3656",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a5f6045-efd5-40b5-a6c5-9963b778cdef.stl100.stl\n",
      "499663d2-aad2-422e-8e66-224c35e68016.stl0-10.stl\n",
      "torch.Size([2, 1, 256, 256, 256])\n",
      "tensor([1.0508, 0.8889])\n",
      "2d2275f7-e595-4ecf-ae66-b03d2508b7f7.stl010.stl\n",
      "2476e817-10bd-4aaa-ac4d-485e9edcddc7.stl010.stl\n",
      "torch.Size([2, 1, 256, 256, 256])\n",
      "tensor([2.5592, 1.9733])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for batch in dataLoader:\n",
    "    inputs, labels = batch\n",
    "    print(inputs.shape)\n",
    "    print(labels)\n",
    "    count += 1\n",
    "    if count >= 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6299a244-806d-4c92-8caf-ee82c1867fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
