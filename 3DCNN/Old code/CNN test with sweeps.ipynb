{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585941ef-25c1-463d-b168-39ce2b474ce1",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6061aa55-251b-4364-b330-988f655c4917",
   "metadata": {
    "id": "6061aa55-251b-4364-b330-988f655c4917",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
   "metadata": {
    "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
    "outputId": "124f3a64-fd41-43f6-8142-e776ca7c728a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
   "metadata": {
    "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
    "outputId": "d4ecf0c7-c798-41ef-9d25-e184eaf4aaf7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangli_824\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f42434-93ee-4923-9809-4aed63ddcce2",
   "metadata": {},
   "source": [
    "# Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2623ad-319a-4cb5-89cf-f279814a831e",
   "metadata": {
    "id": "8d2623ad-319a-4cb5-89cf-f279814a831e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, kernel_size = 3, activation_fn = nn.ReLU()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_pooling_2 = nn.MaxPool3d(kernel_size = 2)\n",
    "\n",
    "        self.up_sampling_2 = nn.Upsample(scale_factor = 2)\n",
    "\n",
    "        self.conv64_1_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 1, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_8_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_8_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_32_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_32_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 32, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_128_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_128_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 128, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv8_256_256 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 256, out_channels = 256, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 256),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv16_384_128 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 384, out_channels = 128, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 128),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv32_160_32 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 160, out_channels = 32, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 32),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_40_8 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 40, out_channels = 8, kernel_size = kernel_size, padding = 'same'),\n",
    "            nn.BatchNorm3d(num_features = 8),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "        self.conv64_8_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels = 8, out_channels = 1, kernel_size = kernel_size, padding = 'same'),\n",
    "            activation_fn\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv64_1_8(x)\n",
    "        x = self.conv64_8_8(x)\n",
    "        feature_map_64 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv32_8_32(x)\n",
    "        x = self.conv32_32_32(x)\n",
    "        feature_map_32 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv16_32_128(x)\n",
    "        x = self.conv16_128_128(x)\n",
    "        feature_map_16 = x.detach()\n",
    "        x = self.max_pooling_2(x)\n",
    "        x = self.conv8_128_256(x)\n",
    "        x = self.conv8_256_256(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_16, x), dim = 1)\n",
    "        x = self.conv16_384_128(x)\n",
    "        x = self.conv16_128_128(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_32, x), dim = 1)\n",
    "        x = self.conv32_160_32(x)\n",
    "        x = self.conv32_32_32(x)\n",
    "        x = self.up_sampling_2(x)\n",
    "        x = torch.cat((feature_map_64, x), dim = 1)\n",
    "        x = self.conv64_40_8(x)\n",
    "        x = self.conv64_8_1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "676a283b-9009-4ac8-8fd3-c1ef8b65c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_loader, optimizer, loss_fn):\n",
    "    cumulative_loss = 0.0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        cumulative_loss += loss.item()\n",
    "        \n",
    "        wandb.log({'batch loss': loss.item()})\n",
    "    return cumulative_loss / len(training_loader), cumulative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
   "metadata": {
    "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config, loss_fn):\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    # initialize a wandb run\n",
    "    wandb.init(config = config)\n",
    "\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    print('config:', config)\n",
    "\n",
    "    # get training loader\n",
    "    training_loader = DataLoader(list(zip(X_train, y_train)), batch_size = config.batch_size, shuffle = True)\n",
    "\n",
    "    # initialize model\n",
    "    if config.activation_fn == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    \n",
    "    if config.activation_fn == 'Sigmoid':\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    \n",
    "    model = ConvNet(kernel_size = config.kernel_size, activation_fn = activation_fn).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config.learning_rate, momentum = 0.9)\n",
    "\n",
    "    for epoch in range(config.epochs_choice):\n",
    "        avg_loss_per_batch, cumulative_loss = train_epoch(model, training_loader, optimizer, loss_fn)\n",
    "        wandb.log({'avg_loss_per_batch': avg_loss_per_batch, 'cumulative_loss': cumulative_loss})\n",
    "        print(f'Loss for epoch {epoch}: {cumulative_loss}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77c5334-2ce1-49ea-8785-c499da625081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(config, model, loss_fn):\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # get testing loader\n",
    "    testing_loader = DataLoader(list(zip(X_test, y_test)), batch_size = config.batch_size, shuffle = True)\n",
    "    \n",
    "    testing_loss = 0.0\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        inputs, labels = data\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        testing_loss += loss.item()\n",
    "    return testing_loss / len(testing_loader), testing_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45e5a4d-fe1f-4629-a456-1865f7e9906b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config = None):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = train(config, loss_fn)\n",
    "    avg_loss_per_batch_test, testing_loss = test(config, model, loss_fn)\n",
    "    wandb.log({'avg_loss_per_batch_test': avg_loss_per_batch_test, 'testing_loss': testing_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca78b2-c4d7-42d8-9892-f9208ea51be7",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ff9159-6663-4950-948f-375de80052aa",
   "metadata": {
    "id": "79ff9159-6663-4950-948f-375de80052aa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = torch.rand((1280, 1, 64, 64, 64), device = device)\n",
    "y = torch.rand((1280, 1, 64, 64, 64), device = device)\n",
    "X_train, X_test = torch.utils.data.random_split(X, [0.8, 0.2])\n",
    "y_train, y_test = torch.utils.data.random_split(y, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3855e-1af6-4dac-a2eb-9afca254bdcd",
   "metadata": {},
   "source": [
    "# Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2403886e-355f-4658-8199-aebb835516bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'testing_loss',\n",
    "    'goal': 'minimize'\n",
    "    }\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'kernel_size': {\n",
    "        'values': [3, 4, 5]\n",
    "    },\n",
    "    'activation_fn': {\n",
    "        'values': ['ReLU', 'Sigmoid']\n",
    "    },\n",
    "    'epochs_choice': {\n",
    "          'values': [5, 10, 20]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'values': [1e-4, 1e-3, 1e-2]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [8, 4]\n",
    "    },\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411fe0-67e5-49c3-b22a-9d5ac1f5abd1",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f5fe4f-57a0-4445-aaec-58183fb12613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: g2wh6a8o\n",
      "Sweep URL: https://wandb.ai/changli_824/CNN_sweep/sweeps/g2wh6a8o\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project = 'CNN_sweep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8f8da-e378-4181-8bcc-fc83a0a26754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\silly bb\\Desktop\\Capstone\\CNN\\wandb\\run-20240120_205458-8ei8xyu2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/changli_824/CNN_sweep/runs/8ei8xyu2' target=\"_blank\">kind-sweep-1</a></strong> to <a href='https://wandb.ai/changli_824/CNN_sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/changli_824/CNN_sweep/sweeps/g2wh6a8o' target=\"_blank\">https://wandb.ai/changli_824/CNN_sweep/sweeps/g2wh6a8o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/changli_824/CNN_sweep' target=\"_blank\">https://wandb.ai/changli_824/CNN_sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/changli_824/CNN_sweep/sweeps/g2wh6a8o' target=\"_blank\">https://wandb.ai/changli_824/CNN_sweep/sweeps/g2wh6a8o</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/changli_824/CNN_sweep/runs/8ei8xyu2' target=\"_blank\">https://wandb.ai/changli_824/CNN_sweep/runs/8ei8xyu2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'activation_fn': 'ReLU', 'batch_size': 8, 'epochs_choice': 5, 'kernel_size': 3, 'learning_rate': 0.0001}\n",
      "Loss for epoch 0: 22.592270016670227\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id = sweep_id, function = evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194b0ce2-ff26-4040-8e72-92f769a3c39c",
   "metadata": {
    "id": "194b0ce2-ff26-4040-8e72-92f769a3c39c"
   },
   "source": [
    "Next Steps:<br>\n",
    "Automate hyperparameter tuning, potentially with weights and biases<br>\n",
    "Understand and figure out ways to limit GPU memory usage<br>\n",
    "Try binary/short inputs<br>\n",
    "Replace dummy data with real data<br>\n",
    "Run with google drive data, get github data set up"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
