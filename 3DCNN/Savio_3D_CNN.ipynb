{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585941ef-25c1-463d-b168-39ce2b474ce1",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061aa55-251b-4364-b330-988f655c4917",
   "metadata": {
    "id": "6061aa55-251b-4364-b330-988f655c4917",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from Savio_Dataset import CustomDataset\n",
    "from Networks import ConvNetScalarLabel256, ConvNetScalarLabel64, MLPBaseline64, count_parameters\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
   "metadata": {
    "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
    "outputId": "124f3a64-fd41-43f6-8142-e776ca7c728a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
   "metadata": {
    "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
    "outputId": "d4ecf0c7-c798-41ef-9d25-e184eaf4aaf7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3855e-1af6-4dac-a2eb-9afca254bdcd",
   "metadata": {},
   "source": [
    "# Parsing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a6355-707c-42fd-ba04-c9dd8a4f1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--kernel_size', type = int, required = True)\n",
    "parser.add_argument('--activation_fn', type = str, required = True)\n",
    "parser.add_argument('--epochs_choice', type = int, required = True)\n",
    "parser.add_argument('--learning_rate', type = float, required = True)\n",
    "parser.add_argument('--batch_size', type = int, required = True)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca78b2-c4d7-42d8-9892-f9208ea51be7",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f81a9-f655-43fd-b48e-2b321014569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(voxel):\n",
    "    # return torch.unsqueeze(torch.tensor(condense_voxel_array(voxel, 64), dtype = torch.float32), 0)\n",
    "    return torch.unsqueeze(torch.tensor(voxel, dtype = torch.float32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2ce47-f930-4911-9852-d4aeeeac9e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "configs = json.load(open('Savio_config.json', 'r'))\n",
    "data_path = configs['data_path']\n",
    "train_parts = configs['train_parts']\n",
    "val_parts = configs['val_parts']\n",
    "resolution = configs['resolution']\n",
    "wandb_path = configs['wandb_path']\n",
    "baseline = configs['baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521cd03-b614-41ce-9fb7-93d1c40393ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data_path = data_path, label_file_path = train_parts, transform = transform, resolution = resolution)\n",
    "dataset_val = CustomDataset(data_path = data_path, label_file_path = val_parts, transform = transform, resolution = resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de22b3-9c5b-42c3-8f34-94abec2fd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd170337-3ce8-47cf-b19b-763e7fc07f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7768965-fb9e-4aec-946a-4b09550e7ae0",
   "metadata": {},
   "source": [
    "# Get Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66289093-d3e6-414e-9796-c08aaa133a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "if baseline = 0:\n",
    "    if resolution == 256:\n",
    "        model_class = ConvNetScalarLabel256\n",
    "    if resolution == 64:\n",
    "        model_class = ConvNetScalarLabel64\n",
    "if baseline == 1:\n",
    "    if resolution == 64:\n",
    "        model_class = MLPBaseline64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99138ba4-a9d8-4108-96da-6b503e54c7f1",
   "metadata": {},
   "source": [
    "# Define Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a283b-9009-4ac8-8fd3-c1ef8b65c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_loader, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_time = 0.0\n",
    "    cumulative_load_time = 0.0\n",
    "    load_start = time.time()\n",
    "    for i, data in enumerate(tqdm(training_loader)):\n",
    "        load_end = time.time()\n",
    "        cumulative_load_time += load_end - load_start\n",
    "        wandb.log({'load_time_train_ms': (load_end - load_start) * 1000})\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.squeeze(labels)\n",
    "\n",
    "        tic = time.time()\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and its gradients\n",
    "        # print('label shape', labels.shape)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        toc = time.time()\n",
    "\n",
    "        # Increment by the mean loss of the batch\n",
    "        cumulative_loss += loss.item()\n",
    "\n",
    "        if i > 10:\n",
    "            cumulative_time += toc - tic\n",
    "            wandb.log({'inference_time_train_ms': (toc - tic) * 1000})\n",
    "        \n",
    "        wandb.log({'batch loss': loss.item()})\n",
    "        load_start = time.time()\n",
    "    return cumulative_loss / len(training_loader), cumulative_time / (len(training_loader) - 10) * 1000, cumulative_load_time / len(training_loader) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c5334-2ce1-49ea-8785-c499da625081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, validation_loader, loss_fn):\n",
    "    model.eval()\n",
    "    validation_loss = 0.0\n",
    "    validation_time = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(tqdm(validation_loader)):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            tic = time.time()\n",
    "            outputs = model(inputs)\n",
    "            toc = time.time()\n",
    "            loss = loss_fn(outputs, labels.float())\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "            if i > 10:\n",
    "                validation_time += toc - tic\n",
    "                wandb.log({'inference_time_validation_ms': (toc - tic) * 1000})\n",
    "    \n",
    "            y_true.extend(labels.cpu().numpy().tolist())\n",
    "            y_pred.extend(outputs.cpu().detach().numpy().tolist())\n",
    "    return validation_loss / len(validation_loader), validation_time / (len(validation_loader) - 10) * 1000, r2_score(y_true = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
   "metadata": {
    "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(args, loss_fn):\n",
    "    \n",
    "    # get training loader\n",
    "    training_loader = DataLoader(dataset, batch_size = args.batch_size, shuffle = True)\n",
    "\n",
    "    # get validation loader\n",
    "    validation_loader = DataLoader(dataset_val, batch_size = args.batch_size, shuffle = True)\n",
    "\n",
    "    # initialize model\n",
    "    if args.activation_fn == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    \n",
    "    if args.activation_fn == 'Sigmoid':\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    \n",
    "    model = model_class(kernel_size = args.kernel_size, activation_fn = activation_fn).to(device)\n",
    "    print(count_parameters(model))\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = args.learning_rate, momentum = 0.9)\n",
    "\n",
    "    for epoch in range(args.epochs_choice):\n",
    "        wandb.log({'epoch': epoch})\n",
    "        # train\n",
    "        tic = time.time()\n",
    "        train_loss, inference_time, load_time = train_epoch(model, training_loader, loss_fn, optimizer)\n",
    "        toc = time.time()\n",
    "        wandb.log({'train_loss': train_loss, 'train_time': round(toc - tic), 'train_time_batch_ms': inference_time, 'load_time_batch_ms': load_time})\n",
    "        print(f'Train loss for epoch {epoch}: {train_loss}, train time for epoch {epoch}: {round(toc - tic)}, average inference time for batch in milliseconds: {inference_time}')\n",
    "\n",
    "        # validate\n",
    "        tic = time.time()\n",
    "        validation_loss, inference_time, r2 = validate(model, validation_loader, loss_fn)\n",
    "        toc = time.time()\n",
    "        wandb.log({'validation_loss': validation_loss, 'r2': r2, 'validate_time': round(toc - tic), 'validate_time_batch_ms': inference_time})\n",
    "        print(f'Validate loss for epoch {epoch}: {validation_loss}, r2 for epoch {epoch}: {r2}, validate time for epoch {epoch}: {round(toc - tic)}, average inference time for batch in milliseconds: {inference_time}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e5a4d-fe1f-4629-a456-1865f7e9906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(args = None):\n",
    "    training_set = train_parts[5:-5]\n",
    "    name = f'3DCNN_{training_set}_{args.kernel_size}_{args.activation_fn}_{args.epochs_choice}_{args.learning_rate}_{args.batch_size}'\n",
    "    # name = '3DCNN runtime testing'\n",
    "    print(name)\n",
    "\n",
    "    config = {\n",
    "        # filename of the training set, '10000' in 'data/10000.json' for example\n",
    "        'training_set': training_set,\n",
    "        'kernel_size': args.kernel_size,\n",
    "        'activation_fn': args.activation_fn,\n",
    "        'epochs_choice': args.epochs_choice,\n",
    "        'learning_rate': args.learning_rate,\n",
    "        'batch_size': args.batch_size,\n",
    "        'architecture': model_class.arch,\n",
    "        'num_parameters': count_parameters(model_class(kernel_size = args.kernel_size))\n",
    "    }\n",
    "    # initialize a wandb run\n",
    "    wandb.init(name = name, project = 'PAPER', config = config, dir = wandb_path)\n",
    "    \n",
    "    loss_fn = nn.L1Loss(reduction = 'mean')\n",
    "    model = evaluate(args, loss_fn)\n",
    "    torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411fe0-67e5-49c3-b22a-9d5ac1f5abd1",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bc578-9432-4dab-88eb-91bafacf5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(args = args)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
