{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585941ef-25c1-463d-b168-39ce2b474ce1",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061aa55-251b-4364-b330-988f655c4917",
   "metadata": {
    "id": "6061aa55-251b-4364-b330-988f655c4917",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import r2_score\n",
    "from Savio_Dataset import CustomDataset\n",
    "from Networks import ConvNetScalarLabel, count_parameters\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
   "metadata": {
    "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
    "outputId": "124f3a64-fd41-43f6-8142-e776ca7c728a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
   "metadata": {
    "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
    "outputId": "d4ecf0c7-c798-41ef-9d25-e184eaf4aaf7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0be766-26cc-41d8-a476-f652fb68d147",
   "metadata": {},
   "source": [
    "# Calculate number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c7b0f4-03b1-4189-9755-486c35c73fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(ConvNetScalarLabel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca78b2-c4d7-42d8-9892-f9208ea51be7",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f81a9-f655-43fd-b48e-2b321014569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(voxel):\n",
    "    # return torch.unsqueeze(torch.tensor(condense_voxel_array(voxel, 64), dtype = torch.float32), 0)\n",
    "    return torch.unsqueeze(torch.tensor(voxel, dtype = torch.float32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2ce47-f930-4911-9852-d4aeeeac9e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "configs = json.load(open('Savio_config.json', 'r'))\n",
    "data_path = configs['data_path']\n",
    "train_parts = configs['train_parts']\n",
    "val_parts = configs['val_parts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0521cd03-b614-41ce-9fb7-93d1c40393ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(data_path = data_path, label_file_path = train_parts, transform = transform)\n",
    "dataset_val = CustomDataset(data_path = data_path, label_file_path = val_parts, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de22b3-9c5b-42c3-8f34-94abec2fd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd170337-3ce8-47cf-b19b-763e7fc07f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99138ba4-a9d8-4108-96da-6b503e54c7f1",
   "metadata": {},
   "source": [
    "# Define Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676a283b-9009-4ac8-8fd3-c1ef8b65c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_loader, optimizer, loss_fn):\n",
    "    cumulative_loss = 0.0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.squeeze(labels)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and its gradients\n",
    "        # print('label shape', labels.shape)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Increment by the mean loss of the batch\n",
    "        cumulative_loss += loss.item()\n",
    "        \n",
    "        wandb.log({'batch loss': loss.item()})\n",
    "    return cumulative_loss / len(training_loader), cumulative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
   "metadata": {
    "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(args, loss_fn):\n",
    "    print(f'3DCNN_{args.kernel_size}_{args.activation_fn}_{args.epochs_choice}_{args.learning_rate}_{args.batch_size}')\n",
    "\n",
    "    # get training loader\n",
    "    training_loader = DataLoader(dataset, batch_size = args.batch_size, shuffle = False)\n",
    "\n",
    "    # initialize model\n",
    "    if args.activation_fn == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    \n",
    "    if args.activation_fn == 'Sigmoid':\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    \n",
    "    model = ConvNetScalarLabel(kernel_size = args.kernel_size, activation_fn = activation_fn).to(device)\n",
    "    print(count_parameters(model))\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = args.learning_rate, momentum = 0.9)\n",
    "\n",
    "    for epoch in range(args.epochs_choice):\n",
    "        tic = time.time()\n",
    "        train_loss, cumulative_loss = train_epoch(model, training_loader, optimizer, loss_fn)\n",
    "        toc = time.time()\n",
    "        wandb.log({'train_loss': train_loss, 'cumulative_loss': cumulative_loss * args.batch_size, 'time': round(toc - tic)})\n",
    "        print(f'Train loss for epoch {epoch}: {train_loss}, cumulative loss for epoch {epoch}: {cumulative_loss * args.batch_size}, time for epoch {epoch}: {round(toc - tic)}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c5334-2ce1-49ea-8785-c499da625081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(args, model, loss_fn):\n",
    "    \n",
    "    # get validation loader\n",
    "    validation_loader = DataLoader(dataset_val, batch_size = args.batch_size, shuffle = False)\n",
    "    \n",
    "    validation_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, data in enumerate(validation_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        validation_loss += loss.item()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy().tolist())\n",
    "        y_pred.extend(outputs.cpu().detach().numpy().tolist())\n",
    "    return validation_loss / len(validation_loader), r2_score(y_true = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e5a4d-fe1f-4629-a456-1865f7e9906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(args = None):\n",
    "    # initialize a wandb run\n",
    "    wandb.init(name = f'3DCNN_{args.kernel_size}_{args.activation_fn}_{args.epochs_choice}_{args.learning_rate}_{args.batch_size}', project = 'PAPER')\n",
    "    \n",
    "    loss_fn = nn.L1Loss(reduction = 'mean')\n",
    "    model = train(args, loss_fn)\n",
    "    torch.save(model, 'model.pt')\n",
    "    validation_loss, r2 = validate(args, model, loss_fn)\n",
    "    wandb.log({'validation_loss': validation_loss, 'r2': r2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3855e-1af6-4dac-a2eb-9afca254bdcd",
   "metadata": {},
   "source": [
    "# Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a6355-707c-42fd-ba04-c9dd8a4f1c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--kernel_size', type = int, required = True)\n",
    "parser.add_argument('--activation_fn', type = str, required = True)\n",
    "parser.add_argument('--epochs_choice', type = int, required = True)\n",
    "parser.add_argument('--learning_rate', type = float, required = True)\n",
    "parser.add_argument('--batch_size', type = int, required = True)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411fe0-67e5-49c3-b22a-9d5ac1f5abd1",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1bc578-9432-4dab-88eb-91bafacf5146",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(args = args)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
