{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "585941ef-25c1-463d-b168-39ce2b474ce1",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6061aa55-251b-4364-b330-988f655c4917",
   "metadata": {
    "id": "6061aa55-251b-4364-b330-988f655c4917",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import r2_score\n",
    "from BinvoxDataset import CustomDataset\n",
    "from Networks import ConvNetScalarLabel, count_parameters\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
   "metadata": {
    "id": "75409c2a-7c7e-454a-b493-a8894b7469ce",
    "outputId": "124f3a64-fd41-43f6-8142-e776ca7c728a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
   "metadata": {
    "id": "6923a256-f4d8-4be9-8cd5-4151db71895e",
    "outputId": "d4ecf0c7-c798-41ef-9d25-e184eaf4aaf7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchangli_824\u001b[0m (\u001b[33madditive-parts\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0be766-26cc-41d8-a476-f652fb68d147",
   "metadata": {},
   "source": [
    "# Calculate number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8c7b0f4-03b1-4189-9755-486c35c73fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "| layers.0.0.weight  |     54     |\n",
      "| layers.0.1.weight  |     2      |\n",
      "|  layers.0.1.bias   |     2      |\n",
      "| layers.2.0.weight  |    216     |\n",
      "| layers.2.1.weight  |     4      |\n",
      "|  layers.2.1.bias   |     4      |\n",
      "| layers.4.0.weight  |    864     |\n",
      "| layers.4.1.weight  |     8      |\n",
      "|  layers.4.1.bias   |     8      |\n",
      "| layers.6.0.weight  |    6912    |\n",
      "| layers.6.1.weight  |     32     |\n",
      "|  layers.6.1.bias   |     32     |\n",
      "| layers.8.0.weight  |   110592   |\n",
      "| layers.8.1.weight  |    128     |\n",
      "|  layers.8.1.bias   |    128     |\n",
      "| layers.10.0.weight |   884736   |\n",
      "| layers.10.1.weight |    256     |\n",
      "|  layers.10.1.bias  |    256     |\n",
      "|  linear_1.weight   |    4096    |\n",
      "|   linear_1.bias    |     16     |\n",
      "|  linear_2.weight   |     16     |\n",
      "|   linear_2.bias    |     1      |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 1008363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1008363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(ConvNetScalarLabel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ca78b2-c4d7-42d8-9892-f9208ea51be7",
   "metadata": {},
   "source": [
    "# Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296f81a9-f655-43fd-b48e-2b321014569f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(voxel):\n",
    "    # return torch.unsqueeze(torch.tensor(condense_voxel_array(voxel, 64), dtype = torch.float32), 0)\n",
    "    return torch.unsqueeze(torch.tensor(voxel, dtype = torch.float32), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e2ce47-f930-4911-9852-d4aeeeac9e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "configs = json.load(open('config.json', 'r'))\n",
    "train_folder_path = configs['train_folder_path']\n",
    "test_folder_path = configs['test_folder_path']\n",
    "train_folder_name = configs['train_folder_name']\n",
    "test_folder_name = configs['test_folder_name']\n",
    "label_file_path = configs['label_file_path']\n",
    "label_type = configs['label_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0521cd03-b614-41ce-9fb7-93d1c40393ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small values of max_count is for debugging and testing. Use max_count = None for full runs for training data.\n",
    "dataset = CustomDataset(input_folder_path = train_folder_path, input_folder_name = train_folder_name, label_file_path = label_file_path, transform = transform, max_count = None, ram_limit = 500, label_type = label_type)\n",
    "dataset_val = CustomDataset(input_folder_path = test_folder_path, input_folder_name = test_folder_name, label_file_path = label_file_path, transform = transform, max_count = None, ram_limit = 500, label_type = label_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9de22b3-9c5b-42c3-8f34-94abec2fd793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22258"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd170337-3ce8-47cf-b19b-763e7fc07f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13943"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99138ba4-a9d8-4108-96da-6b503e54c7f1",
   "metadata": {},
   "source": [
    "# Define Training Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "676a283b-9009-4ac8-8fd3-c1ef8b65c4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, training_loader, optimizer, loss_fn):\n",
    "    cumulative_loss = 0.0\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = torch.squeeze(labels)\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and its gradients\n",
    "        # print('label shape', labels.shape)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        cumulative_loss += loss.item()\n",
    "        \n",
    "        wandb.log({'batch loss': loss.item()})\n",
    "    return cumulative_loss / len(training_loader), cumulative_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
   "metadata": {
    "id": "af6093e9-59db-4985-91a0-cf5d2bb9b3e7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(config, loss_fn):\n",
    "    clear_output(wait = True)\n",
    "    \n",
    "    # initialize a wandb run\n",
    "    wandb.init(config = config)\n",
    "\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    print('config:', config)\n",
    "\n",
    "    # get training loader\n",
    "    training_loader = DataLoader(dataset, batch_size = config.batch_size, shuffle = False)\n",
    "\n",
    "    # initialize model\n",
    "    if config.activation_fn == 'ReLU':\n",
    "        activation_fn = nn.ReLU()\n",
    "    \n",
    "    if config.activation_fn == 'Sigmoid':\n",
    "        activation_fn = nn.Sigmoid()\n",
    "    \n",
    "    model = ConvNetScalarLabel(kernel_size = config.kernel_size, activation_fn = activation_fn).to(device)\n",
    "    print(count_parameters(model))\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = config.learning_rate, momentum = 0.9)\n",
    "\n",
    "    for epoch in range(config.epochs_choice):\n",
    "        tic = time.time()\n",
    "        avg_loss_per_batch, cumulative_loss = train_epoch(model, training_loader, optimizer, loss_fn)\n",
    "        toc = time.time()\n",
    "        wandb.log({'avg_loss_per_batch': avg_loss_per_batch, 'cumulative_loss': cumulative_loss, 'time': round(toc - tic)})\n",
    "        print(f'Loss for epoch {epoch}: {cumulative_loss}, time for epoch {epoch}: {round(toc - tic)}')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77c5334-2ce1-49ea-8785-c499da625081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(config, model, loss_fn):\n",
    "    # copy the config\n",
    "    config = wandb.config\n",
    "    \n",
    "    # get testing loader\n",
    "    testing_loader = DataLoader(dataset_val, batch_size = config.batch_size, shuffle = False)\n",
    "    \n",
    "    testing_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, data in enumerate(testing_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels.float())\n",
    "        testing_loss += loss.item()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy().tolist())\n",
    "        y_pred.extend(outputs.cpu().detach().numpy().tolist())\n",
    "    return testing_loss / len(testing_loader), testing_loss, r2_score(y_true = y_true, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f45e5a4d-fe1f-4629-a456-1865f7e9906b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(config = None):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = train(config, loss_fn)\n",
    "    torch.save(model, 'model.pt')\n",
    "    avg_loss_per_batch_test, testing_loss, r2 = test(config, model, loss_fn)\n",
    "    wandb.log({'avg_loss_per_batch_test': avg_loss_per_batch_test, 'testing_loss': testing_loss, 'r2': r2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b3855e-1af6-4dac-a2eb-9afca254bdcd",
   "metadata": {},
   "source": [
    "# Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2403886e-355f-4658-8199-aebb835516bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'grid'\n",
    "    }\n",
    "metric = {\n",
    "    'name': 'testing_loss',\n",
    "    'goal': 'minimize'\n",
    "    }\n",
    "sweep_config['metric'] = metric\n",
    "parameters_dict = {\n",
    "    'kernel_size': {\n",
    "        'values': [3]\n",
    "    },\n",
    "    'activation_fn': {\n",
    "        'values': ['ReLU']\n",
    "    },\n",
    "    'epochs_choice': {\n",
    "          'values': [5, 10, 15]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'values': [1e-4, 1e-5]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [4]\n",
    "    },\n",
    "}\n",
    "'''\n",
    "parameters_dict = {\n",
    "    'kernel_size': {\n",
    "        'values': [3]\n",
    "    },\n",
    "    'activation_fn': {\n",
    "        'values': ['ReLU']\n",
    "    },\n",
    "    'epochs_choice': {\n",
    "          'values': [5]\n",
    "    },\n",
    "    'learning_rate': {\n",
    "        'values': [1e-5]\n",
    "    },\n",
    "    'batch_size': {\n",
    "        'values': [4]\n",
    "    },\n",
    "}\n",
    "'''\n",
    "sweep_config['parameters'] = parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83411fe0-67e5-49c3-b22a-9d5ac1f5abd1",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74f5fe4f-57a0-4445-aaec-58183fb12613",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: gsng4sjr\n",
      "Sweep URL: https://wandb.ai/additive-parts/CNN_sweep_scalar/sweeps/gsng4sjr\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project = 'CNN_sweep_scalar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fec8f8da-e378-4181-8bcc-fc83a0a26754",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\silly bb\\Desktop\\Capstone\\CNN\\U-Net\\wandb\\run-20240303_131342-rxpdt6yj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/additive-parts/CNN_sweep_scalar/runs/rxpdt6yj' target=\"_blank\">lyric-sweep-6</a></strong> to <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar/sweeps/gsng4sjr' target=\"_blank\">https://wandb.ai/additive-parts/CNN_sweep_scalar/sweeps/gsng4sjr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar' target=\"_blank\">https://wandb.ai/additive-parts/CNN_sweep_scalar</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar/sweeps/gsng4sjr' target=\"_blank\">https://wandb.ai/additive-parts/CNN_sweep_scalar/sweeps/gsng4sjr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar/runs/rxpdt6yj' target=\"_blank\">https://wandb.ai/additive-parts/CNN_sweep_scalar/runs/rxpdt6yj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'activation_fn': 'ReLU', 'batch_size': 4, 'epochs_choice': 15, 'kernel_size': 3, 'learning_rate': 1e-05}\n",
      "+--------------------+------------+\n",
      "|      Modules       | Parameters |\n",
      "+--------------------+------------+\n",
      "| layers.0.0.weight  |     54     |\n",
      "| layers.0.1.weight  |     2      |\n",
      "|  layers.0.1.bias   |     2      |\n",
      "| layers.2.0.weight  |    216     |\n",
      "| layers.2.1.weight  |     4      |\n",
      "|  layers.2.1.bias   |     4      |\n",
      "| layers.4.0.weight  |    864     |\n",
      "| layers.4.1.weight  |     8      |\n",
      "|  layers.4.1.bias   |     8      |\n",
      "| layers.6.0.weight  |    6912    |\n",
      "| layers.6.1.weight  |     32     |\n",
      "|  layers.6.1.bias   |     32     |\n",
      "| layers.8.0.weight  |   110592   |\n",
      "| layers.8.1.weight  |    128     |\n",
      "|  layers.8.1.bias   |    128     |\n",
      "| layers.10.0.weight |   884736   |\n",
      "| layers.10.1.weight |    256     |\n",
      "|  layers.10.1.bias  |    256     |\n",
      "|  linear_1.weight   |    4096    |\n",
      "|   linear_1.bias    |     16     |\n",
      "|  linear_2.weight   |     16     |\n",
      "|   linear_2.bias    |     1      |\n",
      "+--------------------+------------+\n",
      "Total Trainable Params: 1008363\n",
      "1008363\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 0: 528.602385036429, time for epoch 0: 1794\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 1: 347.04452166885676, time for epoch 1: 1786\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 2: 298.3085218421329, time for epoch 2: 1788\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 3: 317.29870247455983, time for epoch 3: 1788\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 4: 271.4445565488495, time for epoch 4: 1793\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 5: 263.69596515341436, time for epoch 5: 1793\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 6: 244.93031768261426, time for epoch 6: 1793\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 7: 229.1313455896816, time for epoch 7: 1806\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 8: 203.98843985319036, time for epoch 8: 1890\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 9: 190.54875551522855, time for epoch 9: 1872\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 10: 179.3672607952758, time for epoch 10: 1852\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 11: 171.53720883871574, time for epoch 11: 2019\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 12: 163.81804167746668, time for epoch 12: 1804\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 13: 160.0300581182746, time for epoch 13: 2467\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n",
      "Processing sample 15000\n",
      "Processing sample 17500\n",
      "Processing sample 20000\n",
      "Loss for epoch 14: 155.34091477944094, time for epoch 14: 2249\n",
      "Processing sample 0\n",
      "Processing sample 2500\n",
      "Processing sample 5000\n",
      "Processing sample 7500\n",
      "Processing sample 10000\n",
      "Processing sample 12500\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_loss_per_batch</td><td>█▅▄▄▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>avg_loss_per_batch_test</td><td>▁</td></tr><tr><td>batch loss</td><td>█▃▂▁▂▄▃▃▃▂▄▁▃▂▁▂▃▁▁▃▂▁▂▂▂▂▂▁▁▂▂▁▁▂▄▂▁▁▂▁</td></tr><tr><td>cumulative_loss</td><td>█▅▄▄▃▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>r2</td><td>▁</td></tr><tr><td>testing_loss</td><td>▁</td></tr><tr><td>time</td><td>▁▁▁▁▁▁▁▁▂▂▂▃▁█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_loss_per_batch</td><td>0.02791</td></tr><tr><td>avg_loss_per_batch_test</td><td>0.07773</td></tr><tr><td>batch loss</td><td>0.01802</td></tr><tr><td>cumulative_loss</td><td>155.34091</td></tr><tr><td>r2</td><td>0.15561</td></tr><tr><td>testing_loss</td><td>270.95577</td></tr><tr><td>time</td><td>2249</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lyric-sweep-6</strong> at: <a href='https://wandb.ai/additive-parts/CNN_sweep_scalar/runs/rxpdt6yj' target=\"_blank\">https://wandb.ai/additive-parts/CNN_sweep_scalar/runs/rxpdt6yj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240303_131342-rxpdt6yj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id = sweep_id, function = evaluate)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
